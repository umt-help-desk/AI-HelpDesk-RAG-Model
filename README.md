# AI HelpDesk

## ğŸ“Œ Overview

The **AI HelpDesk** is an intelligent assistant designed to help university students with their academic inquiries, including university policies, student guidelines, and general academic-related questions. The chatbot integrates **web scraping, document embeddings, and Large Language Models (LLMs)** to provide precise and contextually relevant answers.

---

## ğŸ§© Features

- âœ… **Web Scraping**: Dynamically extracts data from university websites using **Playwright** & **BeautifulSoup**.
- âœ… **AI-Powered Answering**: Uses **BART-Large-CNN** for summarization & **LaMini-GPT-1.5B** for response generation.
- âœ… **Efficient Retrieval**: Stores embeddings in **ChromaDB** for fast and accurate search.
- âœ… **Scalable & Fast**: Supports large datasets and multiple queries efficiently.
- âœ… **User-Friendly UI**: Built with **Streamlit** for an intuitive chatbot interface.

---

## ğŸ› ï¸ Tech Stack

- **Python** (Primary Language)
- **Playwright & BeautifulSoup** (Web Scraping)
- **LangChain** (Retrieval & Document Processing)
- **Hugging Face Transformers** (LLMs for Answering)
- **ChromaDB** (Vector Database)
- **Streamlit** (Frontend UI for Chatbot)

---

## âš™ï¸ How It Works

### 1ï¸âƒ£ Data Collection
- Scrapes university web pages using **Playwright** & **BeautifulSoup**.
- Extracts text and stores it in structured files.

### 2ï¸âƒ£ Document Processing & Embeddings
- Loads university handbooks, student guidelines, and scraped data.
- Splits text into smaller chunks & creates vector embeddings using **sentence-transformers/all-mpnet-base-v2**.
- Stores embeddings in **ChromaDB** for efficient retrieval.

### 3ï¸âƒ£ Query Processing
- User asks a question via **Streamlit UI**.
- Retrieves the most relevant context using **semantic search** on **ChromaDB**.
- Summarizes retrieved content with **BART-Large-CNN**.
- Generates a final answer using **LaMini-GPT-1.5B**.

---

## ğŸ“‚ Folder Structure

```
ğŸ“¦ AI-Help-Desk 
 â”£ ğŸ“‚ bart-large-cnn  # Pre-trained Summarization Model
 â”£ ğŸ“‚ LaMini-GPT-1.5B  # Pre-trained LLM for Response Generation
 â”£ ğŸ“‚ chroma_db  # Vector Database Storage
 â”£ ğŸ“‚ Data  # Scraped Data and Documents
 â”ƒ â”£ ğŸ“œ DataSet.pdf
 â”ƒ â”£ ğŸ“œ Participant-Guide.pdf
 â”ƒ â”— ğŸ“œ Handbook-Undergraduate-Studies.pdf
 â”£ ğŸ“‚ Notebooks  # Jupyter Notebooks for Preprocessing
 â”ƒ â”£ ğŸ“œ clean_scraping_data.ipynb
 â”ƒ â”£ ğŸ“œ data_preprocessing.ipynb
 â”ƒ â”— ğŸ“œ csv_to_pdf.ipynb
 â”£ ğŸ“œ scrapping.py  # Web Scraper
 â”£ ğŸ“œ embeddings.py  # Embedding Generator
 â”£ ğŸ“œ utils.py  # Context Retrieval & Summarization
 â”£ ğŸ“œ main.py  # Streamlit UI for Chatbot
 â”£ ğŸ“œ design.py  # UI Design
 â”£ ğŸ“œ requirements.txt  # Dependencies
 â”£ ğŸ“œ LICENSE  # Project License
 â”— ğŸ“œ README.md  # Documentation
```

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/umt-help-desk/AI-HelpDesk-RAG-Model.git
cd AI-HelpDesk-RAG-Model
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download LLMs (Pre-Trained Models)
```bash
git clone https://huggingface.co/facebook/bart-large-cnn

git clone https://huggingface.co/MBZUAI/LaMini-GPT-1.5B
```
âš ï¸ Ensure both `bart-large-cnn` and `LaMini-GPT-1.5B` folders are in the project directory.

### 4ï¸âƒ£ Run Web Scraper (Optional)
```bash
python scrapping.py
```

### 5ï¸âƒ£ Generate Embeddings & Store in ChromaDB
```bash
python embeddings.py
```

### 6ï¸âƒ£ Start the Chatbot
```bash
streamlit run main.py
```

---

## ğŸ” Troubleshooting

### ğŸ”¹ Module Not Found: `ModuleNotFoundError: No module named 'playwright'`
```bash
pip install playwright
playwright install
```

### ğŸ”¹ Out of Memory (OOM) Error
- Reduce `chunk_size` in `embeddings.py`.
- Use `device='cpu'` in models if running on a low-GPU machine.

### ğŸ”¹ No Response from Chatbot
- Ensure both LLMs are downloaded and placed in the project directory.
- Run `python embeddings.py` again before starting `main.py`.

### ğŸ”¹ Missing Dependencies / Python Version Mismatch
```bash
conda create -n ai-help-desk python=3.10.12
conda activate ai-help-desk
pip install -r requirements.txt
```

---

## ğŸ¤ Contributing

We welcome contributions! If you'd like to improve the chatbot, follow these steps:

1. **Fork** the repository.
2. **Create a new branch**: `git checkout -b feature-branch`
3. **Commit your changes**: `git commit -m 'Added new feature'`
4. **Push to the branch**: `git push origin feature-branch`
5. **Create a Pull Request**

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the full license details in the [LICENSE](LICENSE) file.

---

## ğŸ“¬ Contributors Contact
ğŸ‘¤ **Muhammad Rehan Hanif**  
ğŸ“§ Email: [rehan.hanif2004@gmail.com](mailto:rehan.hanif2004@gmail.com)  
ğŸ“‚ GitHub: [MRH-66](https://github.com/MRH-66)

ğŸ‘¤ **Syed Burhan Ahmad**  
ğŸ“§ Email: [syedburhanahmedd@gmail.com](mailto:syedburhanahmedd@gmail.com)  
ğŸ“‚ GitHub: [SyedBurhanAhmed](https://github.com/SyedBurhanAhmed)

ğŸ‘¤ **Kaleemullah Younas**  
ğŸ“§ Email: [kaleemullahyouus123@gmail.com](mailto:kaleemullahyouus123@gmail.com)  
ğŸ“‚ GitHub: [Kaleemullah-Younas](https://github.com/Kaleemullah-Younas)

ğŸ‘¤ **Syed Arman Mehdi Kazmi**  
ğŸ“§ Email: [kazmiarmanmehdi@gmail.com](mailto:kazmiarmanmehdi@gmail.com)  
ğŸ“‚ GitHub: [ArmanMehdi](https://github.com/ArmanMehdi)

ğŸ‘¤ **Ali Hassan**  
ğŸ“§ LinkedIN: [Ali Hassan](https://www.linkedin.com/in/ali-hassan-96b230244/)  
ğŸ“‚ GitHub: [logsaviour](https://github.com/logsaviour)

---

## ğŸŒŸ Acknowledgments

- [Hugging Face](https://huggingface.co/) - Pre-trained LLMs
- [LangChain](https://python.langchain.com/) - Efficient Context Retrieval
- [Streamlit](https://streamlit.io/) - UI for Chatbot
- [ChromaDB](https://www.trychroma.com/) - Vector Database
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) - Web Scraping

### ğŸ“ AI-Powered University Assistance
